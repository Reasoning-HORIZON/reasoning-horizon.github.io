<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <meta name="title" content="R-HORIZON: How Far Can Your Large Reasoning Model Really Go in Breadth and Depth?">
  <meta name="description" content="R-HORIZON is a method and benchmark designed to evaluate and enhance Large Reasoning Models (LRMs) on complex, long-horizon reasoning tasks via query composition.">
  <meta name="keywords" content="Large Reasoning Models, LRMs, Long-Horizon Reasoning, Benchmark, Chain-of-Thought, RLVR, Query Composition, AIME">
  <meta name="author" content="Yi Lu, Jianing Wang, Linsen Guo, Wei He, Hongyin Tang, Tao Gui, Xuanjing Huang, Xuezhi Cao, Wei Wang, Xunliang Cai">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">

  <meta property="og:type" content="article">
  <meta property="og:site_name" content="Fudan University & Meituan">
  <meta property="og:title" content="R-HORIZON: How Far Can Your Large Reasoning Model Really Go in Breadth and Depth?">
  <meta property="og:description" content="R-HORIZON is a method and benchmark designed to evaluate and enhance Large Reasoning Models (LRMs) on complex, long-horizon reasoning tasks via query composition.">
  <meta property="og:url" content="https://reasoning-horizon.github.io">
  <meta property="og:image" content="static/images/mainfig.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="R-HORIZON: Overview of the Query Composition Method.">
  <meta property="article:published_time" content="2025-10-09T00:00:00.000Z">
  <meta property="article:author" content="Yi Lu">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="LRM">
  <meta property="article:tag" content="Long-Horizon Reasoning">


  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <title>R-HORIZON: How Far Can Your Large Reasoning Model Really Go in Breadth and Depth?</title>

  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">

  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>

  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">

  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>

</head>

<body>
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>


  <main id="main-content">
    <main id="main-content">
      <section class="hero">
        <div class="hero-body">
          <div class="container is-max-desktop">
            <div class="columns is-centered">
              <div class="column has-text-centered">
                <h1 class="title is-1 publication-title">
                  <span style="display: flex; align-items: center; justify-content: center;">
                    <img src="static/images/problem-solving.png" alt="logo" width="60" style="vertical-align: middle; margin-right: 10px;">
                    R-HORIZON
                  </span>
                  How Far Can Your Large Reasoning Model Really Go in Breadth and Depth?</h1>
                <div class="is-size-5 publication-authors">
                  <span class="author-block">
                    <a href="https://github.com/LuLuLuyi" target="_blank">Yi Lu</a>,
                  </span>
                  <span class="author-block">
                    <a href="https://wjn1996.github.io/" target="_blank">Jianing Wang</a><sup>†</sup>,
                  </span>
                  <span class="author-block">
                    Linsen Guo,
                  </span>
                  <span class="author-block">
                    Wei He,
                  </span>
                  <span class="author-block">
                    Hongyin Tang,
                  </span>
                  <br>
                  <span class="author-block">
                    Tao Gui,
                  </span>
                  <span class="author-block">
                    Xuanjing Huang,
                  </span>
                  <span class="author-block">
                    Xuezhi Cao,
                  </span>
                  <span class="author-block">
                    Wei Wang<sup>†</sup>,
                  </span>
                  <span class="author-block">
                    Xunliang Cai
                  </span>
                </div>
    
                <div class="is-size-5 publication-authors">
                  <span class="author-block">
                    Fudan University
                    ,
                    Meituan
                  </span>
                  <br>
                  <span class="author-block">
                    <small>†Correspondence to: <code>lygwjn@gmail.com</code>, <code>wangwei432@meituan.com</code></small>
                  </span>
                  <br>
                </div>
    
                <div class="column has-text-centered">
                  <div class="publication-links">
                    <span class="link-block">
                      <a href="[您的 arXiv PDF 链接，替换 TBD]" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          📃
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>
    
                    <span class="link-block">
                      <a href="https://huggingface.co/collections/lulululuyi/r-horzion-68e62c04ccaa96434133d321" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          🤗
                        </span>
                        <span>Dataset</span>
                      </a>
                    </span>
    
                    <span class="link-block">
                      <a href="https://github.com/LuLuLuyi/R-HORIZON" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fab fa-github"></i>
                        </span>
                        <span>Code</span>
                      </a>
                    </span>
    
                    <span class="link-block">
                      <a href="[您的 arXiv Abstract 链接，替换 TBD]" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="ai ai-arxiv"></i>
                        </span>
                        <span>arXiv</span>
                      </a>
                    </span>
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </section>
    
      <section id="abstract" class="section hero is-light">
        <div class="container is-max-desktop">
          <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
              <h2 class="title is-3">Abstract</h2>
              <div class="content has-text-justified">
                <p>
                  Recent trends in test-time scaling for reasoning models (e.g., OpenAI o1, DeepSeek-R1) have led to remarkable improvements through long Chain-of-Thought (CoT). However, existing benchmarks mainly focus on immediate, single-horizon tasks, failing to adequately evaluate models’ ability to understand and respond to complex, long-horizon scenarios. To address this incomplete evaluation of Large Reasoning Models (LRMs), we propose R-HORIZON, a method designed to stimulate long-horizon reasoning behaviors in LRMs through query composition. Based on R-HORIZON, we construct a long-horizon reasoning benchmark, comprising complex multi-step reasoning tasks with interdependent problems that span long reasoning horizons. Through comprehensive evaluation of LRMs using the R-HORIZON benchmark, we find that even the most advanced LRMs suffer significant performance degradation. Our analysis reveals that LRMs exhibit limited effective reasoning length and struggle to allocate thinking budget across multiple problems appropriately. Recognizing these limitations, we use R-HORIZON to construct long-horizon reasoning data for reinforcement learning with verified rewards (RLVR). Compared to training with single-horizon data, RLVR with R-HORIZON not only substantially improves performance on the multi-horizon reasoning tasks, but also promotes accuracy on standard reasoning tasks (+7.5 on AIME2024). These results position R-HORIZON as a scalable, controllable, and low-cost paradigm for enhancing and evaluating the long-horizon reasoning capabilities of LRMs.
                </p>
                <p>
                  <img src="static/images/mainfig.png" alt="R-HORIZON Concept Illustration" class="blend-img-background center-image" style="max-width: 100%; height: auto;" loading="lazy" />
                </p>
              </div>
            </div>
          </div>
        </div>
      </section>
    ---

    <section id="overview" class="section hero is-small">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-full">
            <div class="content">
              <h2 class="title is-3">Overview</h2>
              <div class="level-set has-text-justified">
                <p>
                  Recent advances in reasoning-focused language models (e.g., OpenAI o1, DeepSeek-R1) have demonstrated remarkable improvements through test-time scaling and long Chain-of-Thought (CoT). However, existing benchmarks primarily focus on immediate, single-horizon tasks, failing to adequately evaluate models' ability to handle complex, long-horizon scenarios.
                </p>
                <p>
                  To address these limitations, we introduce <b>R-HORIZON</b>, which:
                  <ul>
                    <li>Transforms isolated problems into <b>complex multi-step reasoning scenarios</b> through query composition.</li>
                    <li>Establishes the <b>R-HORIZON Benchmark</b> comprising 6 representative datasets from mathematics, code generation, and agent applications.</li>
                    <li>Enables <b>reinforcement learning with verified rewards (RLVR)</b> using long-horizon reasoning data.</li>
                  </ul>
                  The diagram below illustrates our method of transforming single problems into complex chained scenarios.
                </p>
                <img src="static/images/method_fig.png" alt="R-HORIZON Method Diagram" class="blend-img-background center-image" style="max-width: 90%; height: auto; display: block; margin: 0 auto;" loading="lazy" />
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    ---

    <section id="evaluation" class="section hero is-small is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-full">
            <div class="content">
              <h2 class="title is-3">Evaluation Results</h2>
              <div class="level-set has-text-justified">
                <p>
                  We evaluate 20+ state-of-the-art Large Reasoning Models (LRMs) on the R-HORIZON Benchmark, revealing a <b>significant performance degradation</b> as reasoning horizons increase. Key findings from our benchmark evaluation include:
                </p>
                <ul>
                  <li><b>Universal Performance Degradation</b>: Even the most powerful models suffer severe drops as problem count increases. For instance, DeepSeek-R1 drops from 87.3% (single problem) to 24.6% (5 problems) on AIME25.</li>
                  <li><b>Model Size Matters</b>: Larger models exhibit more resilience to multi-horizon challenges.</li>
                  <li><b>Task-Dependent Degradation</b>: Code generation tasks show steeper performance declines compared to mathematics. Many reasoning models lose their tool-calling abilities in web search scenarios.</li>
                </ul>
                <img src="static/images/result_fig.png" alt="R-HORIZON Benchmark Results" class="blend-img-background center-image" style="max-width: 90%; height: auto; display: block; margin: 0 auto;" loading="lazy" />
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    ---

    <section id="training" class="section hero is-small">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-full">
            <div class="content">
              <h2 class="title is-3">Training with R-HORIZON</h2>
              <div class="level-set has-text-justified">
                <p>
                  We use R-HORIZON composed data for <b>Reinforcement Learning with Verified Rewards (RLVR)</b>. Training with this long-horizon data yields substantial improvements on both single and multi-horizon reasoning tasks, demonstrating the effectiveness of our method for enhancing LRM capabilities.
                </p>
                <p>
                  <b>Training Results Highlights:</b>
                  <ul>
                    <li><b>Dual Performance Gains</b>: Training with 2-composed problems significantly improves both multi-horizon reasoning (<b>+17.4 points</b> on AIME24 n=2) and single-problem performance (<b>+7.5 points</b> on AIME24 original).</li>
                    <li><b>Scalable Complexity</b>: Increasing composition complexity (n=4) enhances the model's ability to handle problems requiring more reasoning steps, achieving <b>50.6%</b> on Math500 (n=8).</li>
                  </ul>
                </p>
                <img src="static/images/skywork_n1_n2_comparison.png" alt="Training Comparison Plot" class="blend-img-background center-image" style="max-width: 90%; height: auto; display: block; margin: 0 auto;" loading="lazy" />
                
                <div style="overflow-x: auto;">
                  <table class="leaderboard-table" style="border-collapse: collapse; width: 100%; text-align: center; font-size: 0.9em;">
                    
                    <caption>Results of different number of composed queries and reward function</caption>
                    
                    <thead>
                      <tr style="border-top: 2px solid #000; border-bottom: 2px solid #000;">
                        <th rowspan="2" style="width: 15%; padding: 5px; border: none; text-align: left;"></th>
                        <th colspan="2" style="border-right: 1px solid #ccc;"><b>MATH500</b></th>
                        <th colspan="2" style="border-right: 1px solid #ccc;"><b>AIME24</b></th>
                        <th colspan="2" style="border-right: 1px solid #ccc;"><b>AIME25</b></th>
                        <th colspan="2" style="border-right: 1px solid #ccc;"><b>AMC23</b></th>
                        <th colspan="2" style="border: none;"><b>Avg.</b></th>
                      </tr>
                      
                      <tr style="border-bottom: 1px solid #000;">
                        <th style="font-weight: bold; padding: 5px 2px;">Origin</th>
                        <th style="font-weight: bold; padding: 5px 2px; border-right: 1px solid #ccc;">n=8</th>
                        <th style="font-weight: bold; padding: 5px 2px;">Origin</th>
                        <th style="font-weight: bold; padding: 5px 2px; border-right: 1px solid #ccc;">n=2</th>
                        <th style="font-weight: bold; padding: 5px 2px;">Origin</th>
                        <th style="font-weight: bold; padding: 5px 2px; border-right: 1px solid #ccc;">n=2</th>
                        <th style="font-weight: bold; padding: 5px 2px;">Origin</th>
                        <th style="font-weight: bold; padding: 5px 2px; border-right: 1px solid #ccc;">n=2</th>
                        <th style="font-weight: bold; padding: 5px 2px;">Origin</th>
                        <th style="font-weight: bold; padding: 5px 2px;">Multi</th>
                      </tr>
                    </thead>
                    
                    <tbody>
                      <tr>
                        <td style="text-align: left; padding: 5px;">R1-Qwen-7B</td>
                        <td>93.6</td>
                        <td style="background-color: #e0f2ff; border-right: 1px solid #ccc;">11.8</td>
                        <td>48.3</td>
                        <td style="background-color: #e0f2ff; border-right: 1px solid #ccc;">16.4</td>
                        <td>33.3</td>
                        <td style="background-color: #e0f2ff; border-right: 1px solid #ccc;">3.5</td>
                        <td>90.2</td>
                        <td style="background-color: #e0f2ff; border-right: 1px solid #ccc;">48.8</td>
                        <td>66.4</td>
                        <td style="background-color: #e0f2ff;">20.1</td>
                      </tr>
                      
                      <tr>
                        <td style="text-align: left; padding: 5px;">Baseline (n=1)</td>
                        <td><b>95.6</b></td>
                        <td style="background-color: #e0f2ff; border-right: 1px solid #ccc;">8.4</td>
                        <td>57.9</td>
                        <td style="background-color: #e0f2ff; border-right: 1px solid #ccc;">16.7</td>
                        <td>47.9</td>
                        <td style="background-color: #e0f2ff; border-right: 1px solid #ccc;">5.1</td>
                        <td><b>95.9</b></td>
                        <td style="background-color: #e0f2ff; border-right: 1px solid #ccc;">55.0</td>
                        <td>74.3</td>
                        <td style="background-color: #e0f2ff;">21.3</td>
                      </tr>
                      
                      <tr>
                        <td style="text-align: left; padding: 5px;">R-HORIZON (n=2)</td>
                        <td>95.4</td>
                        <td style="background-color: #e0f2ff; border-right: 1px solid #ccc;">21.4</td>
                        <td><b>65.4</b></td>
                        <td style="background-color: #e0f2ff; border-right: 1px solid #ccc;">34.1</td>
                        <td><b>49.6</b></td>
                        <td style="background-color: #e0f2ff; border-right: 1px solid #ccc;">10.0</td>
                        <td>94.1</td>
                        <td style="background-color: #e0f2ff; border-right: 1px solid #ccc;">80.6</td>
                        <td><b>76.1</b></td>
                        <td style="background-color: #e0f2ff;">36.5</td>
                      </tr>
                      
                      <tr>
                        <td style="text-align: left; padding: 5px;">R-HORIZON (n=4)</td>
                        <td>94.6</td>
                        <td style="background-color: #e0f2ff; border-right: 1px solid #ccc;"><b>50.6</b></td>
                        <td>62.9</td>
                        <td style="background-color: #e0f2ff; border-right: 1px solid #ccc;"><b>34.8</b></td>
                        <td>45.4</td>
                        <td style="background-color: #e0f2ff; border-right: 1px solid #ccc;"><b>8.1</b></td>
                        <td>91.9</td>
                        <td style="background-color: #e0f2ff; border-right: 1px solid #ccc;"><b>79.1</b></td>
                        <td>73.7</td>
                        <td style="background-color: #e0f2ff;"><b>43.2</b></td>
                      </tr>
                    </tbody>
                    
                    <tfoot>
                      <tr>
                        <td colspan="11" style="border-top: 2px solid #000; padding: 0;"></td>
                      </tr>
                    </tfoot>
                  </table>
                </div>

              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    ---
    
    <section id="key-findings" class="section hero is-small">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-full">
            <div class="content has-text-justified">
              <h2 class="title is-3 has-text-centered">Key Findings</h2>

              <h3 class="title is-4">1. Limited Effective Reasoning Length</h3>
              <p>
                As the number of interdependent problems increases, Large Reasoning Models (LRMs) struggle to maintain their performance. The gap between actual and theoretical accuracy widens significantly, indicating that models cannot sustain their original performance over longer reasoning horizons. 
              </p>
              <ul>
                <li>Model errors stabilize within a certain context range. For instance, the smaller 7B model's primary error range is (4-6k tokens), while the larger 32B model's range is extended to (8-10k tokens), suggesting <b>larger models possess a longer effective reasoning boundary</b>.</li>
              </ul>

              <p>
                <img src="static/images/math500_aime_four_plots.png" alt="Analysis of accuracy and error position with R1-Qwen-7B and R1-Qwen-32B" class="blend-img-background center-image" style="max-width: 100%; height: auto; display: block; margin: 0 auto;" loading="lazy" />
              </p>

              <h3 class="title is-4">2. Localized Reflection Behavior</h3>
              <p>
                Models' reflection frequency increases and then converges as the number of problems grows. However, over half of the complex tasks lack any <b>long-range reflection</b> (reflection that spans beyond the current problem), indicating that the reflection mechanism in current LRMs is <b>highly localized</b> and insufficient for long-horizon scenarios.
              </p>

              <p>
                <img src="static/images/math500_reflection_analysis.png" alt="Reflection analysis on MATH500 dataset" class="blend-img-background center-image" style="max-width: 90%; height: auto; display: block; margin: 0 auto;" loading="lazy" />
              </p>


              <h3 class="title is-4">3. Inefficient Thinking Budget Allocation</h3>
              <p>
                Current mainstream LRMs, including state-of-the-art models like DeepSeek-R1, exhibit an inability to effectively allocate their thinking budget across the reasoning horizon. They tend to <b>over-allocate tokens to early reasoning stages</b>, failing to distribute resources reasonably to subsequent, critical problems.
              </p>
              
              <p>
                <img src="static/images/aime24_token_boxplot_analysis.png" alt="The thinking budget allocation for different query configurations across models" class="blend-img-background center-image" style="max-width: 90%; height: auto; display: block; margin: 0 auto;" loading="lazy" />
              </p>

              <hr>

              <h3 class="title is-4">4. Impact of R-HORIZON Training </h3>
              <p>
                Training models with R-HORIZON composed data (using Reinforcement Learning with Verified Rewards) promotes significantly more <b>efficient and robust reasoning</b> across multiple metrics:
              </p>
              <ul>
                <li><b>Improved Performance:</b> Training significantly improves model performance on composed tasks and shows better generalization to longer horizons, while alleviating the "overthinking" phenomenon (generating shorter, more efficient responses).</li>
                <li><b>Better Allocation:</b> Models learn a more reasonable <b>token budget allocation</b> across multi-step problems.</li>
                <li><b>Longer Reflection:</b> R-HORIZON facilitates engaging in <b>longer-range reflection</b> with increasing frequency, directly improving performance on long-horizon reasoning.</li>
              </ul>

              <p>
                <img src="static/images/four_analysis_horizontal_compact.png" alt="Analysis of reinforcement learning effects with single and composed datasets" class="blend-img-background center-image" style="max-width: 100%; height: auto; display: block; margin: 0 auto;" loading="lazy" />
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>

    ---

    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <div class="bibtex-header">
          <h2 class="title">BibTeX</h2>
          <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
            <i class="fas fa-copy"></i>
            <span class="copy-text">Copy</span>
          </button>
        </div>
        <pre id="bibtex-code"><code>@article{lu2025rhorizon,
  title={R-HORIZON: How Far Can Your Large Reasoning Model Really Go in Breadth and Depth?},
  author={Lu, Yi and Wang, Jianing and Guo, Linsen and He, Wei and Tang, Hongyin and Gui, Tao and Huang, Xuanjing and Cao, Xuezhi and Wang, Wei and Cai, Xunliang},
  journal={arXiv preprint arXiv:[请替换为您的 arXiv ID]},
  year={2025}
}
</code></pre>
      </div>
    </section>
    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">

              <p>
                This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                  target="_blank">Academic Project Page Template</a> which was adopted from the <a
                  href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              </p>

            </div>
          </div>
        </div>
      </div>
    </footer>

    </main>
</body>

</html>