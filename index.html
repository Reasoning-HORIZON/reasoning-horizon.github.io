<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <meta name="title" content="R-HORIZON: How Far Can Your Large Reasoning Model Really Go in Breadth and Depth?">
  <meta name="description" content="R-HORIZON is a method and benchmark designed to evaluate and enhance Large Reasoning Models (LRMs) on complex, long-horizon reasoning tasks via query composition.">
  <meta name="keywords" content="Large Reasoning Models, LRMs, Long-Horizon Reasoning, Benchmark, Chain-of-Thought, RLVR, Query Composition, AIME">
  <meta name="author" content="Yi Lu, Jianing Wang, Linsen Guo, Wei He, Hongyin Tang, Tao Gui, Xuanjing Huang, Xuezhi Cao, Wei Wang, Xunliang Cai">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">

  <meta property="og:type" content="article">
  <meta property="og:site_name" content="Fudan University & Meituan">
  <meta property="og:title" content="R-HORIZON: How Far Can Your Large Reasoning Model Really Go in Breadth and Depth?">
  <meta property="og:description" content="R-HORIZON is a method and benchmark designed to evaluate and enhance Large Reasoning Models (LRMs) on complex, long-horizon reasoning tasks via query composition.">
  <meta property="og:url" content="https://reasoning-horizon.github.io">
  <meta property="og:image" content="static/images/mainfig.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="R-HORIZON: Overview of the Query Composition Method.">
  <meta property="article:published_time" content="2025-10-09T00:00:00.000Z">
  <meta property="article:author" content="Yi Lu">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="LRM">
  <meta property="article:tag" content="Long-Horizon Reasoning">


  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <title>R-HORIZON: How Far Can Your Large Reasoning Model Really Go in Breadth and Depth?</title>

  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style"
    onload="this.onload=null;this.rel='stylesheet'">

  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>

  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">

  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>

</head>

<body>
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>


  <main id="main-content">
    <section class="hero">
      <div class="hero-body">
        <div class="container is-max-desktop">
          <div class="columns is-centered">
            <div class="column has-text-centered">
              <h1 class="title is-1 publication-title">R-HORIZON: <br>
                How Far Can Your Large Reasoning Model Really Go in Breadth and Depth?</h1>
              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <a href="[Yi Lu's Personal Link]" target="_blank">Yi Lu</a>$^{1,2}$,
                </span>
                <span class="author-block">
                  <a href="[Jianing Wang's Personal Link]" target="_blank">Jianing Wang</a>$^{2}$\textsuperscript{\(\dagger,\ast\)},
                </span>
                <span class="author-block">
                  <a href="[Linsen Guo's Personal Link]" target="_blank">Linsen Guo</a>$^{2}$,
                </span>
                <span class="author-block">
                  <a href="[Wei He's Personal Link]" target="_blank">Wei He</a>$^{1,2}$,
                </span>
                <span class="author-block">
                  <a href="[Hongyin Tang's Personal Link]" target="_blank">Hongyin Tang</a>$^{2}$,
                </span>
                <br>
                <span class="author-block">
                  <a href="[Tao Gui's Personal Link]" target="_blank">Tao Gui</a>$^{1}$,
                </span>
                <span class="author-block">
                  <a href="[Xuanjing Huang's Personal Link]" target="_blank">Xuanjing Huang</a>$^{1}$,
                </span>
                <span class="author-block">
                  <a href="[Xuezhi Cao's Personal Link]" target="_blank">Xuezhi Cao</a>$^{2}$,
                </span>
                <span class="author-block">
                  <a href="[Wei Wang's Personal Link]" target="_blank">Wei Wang</a>$^{2}$\textsuperscript{\(\ast\)},
                </span>
                <span class="author-block">
                  <a href="[Xunliang Cai's Personal Link]" target="_blank">Xunliang Cai</a>$^{2}$
                </span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  $^{1}$<a href="https://www.fudan.edu.cn/" target="_blank">Fudan University</a>
                  \,
                  $^{2}$<a href="https://www.meituan.com/" target="_blank">Meituan</a>
                </span>
                <br>
                <span class="author-block">
                  <small>\textsuperscript{\(\ast\)}Corresponding authors. Correspondence to: <code>lygwjn@gmail.com</code>, <code>wangwei432@meituan.com</code></small>
                </span>
                <br>
                <span class="author-block">
                  <small><a href="https://github.com/LuLuLuyi/R-HORIZON" target="_blank">https://github.com/LuLuLuyi/R-HORIZON</a></small>
                </span>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <span class="link-block">
                    <a href="[您的 arXiv PDF 链接，替换 TBD]" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        📃
                      </span>
                      <span>Paper</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="[您的 Dataset 链接，替换 TBD]" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        💾
                      </span>
                      <span>Dataset</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="https://github.com/LuLuLuyi/R-HORIZON" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>

                  <span class="link-block">
                    <a href="[您的 arXiv Abstract 链接，替换 TBD]" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv</span>
                    </a>
                  </span>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    <section id="abstract" class="section hero is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h2 class="title is-3">Abstract</h2>
            <div class="content has-text-justified">
              <p>
                Recent trends in test-time scaling for reasoning models (e.g., OpenAI o1, DeepSeek-R1) have led to remarkable improvements through long Chain-of-Thought (CoT). However, existing benchmarks mainly focus on immediate, single-horizon tasks, failing to adequately evaluate models’ ability to understand and respond to complex, long-horizon scenarios. To address this incomplete evaluation of Large Reasoning Models (LRMs), we propose <b>R-HORIZON</b>, a method designed to stimulate long-horizon reasoning behaviors in LRMs through **query composition**. Based on R-HORIZON, we construct a long-horizon reasoning benchmark, comprising complex multi-step reasoning tasks with interdependent problems that span long reasoning horizons. Through comprehensive evaluation of LRMs using the R-HORIZON benchmark, we find that even the most advanced LRMs suffer significant performance degradation. Our analysis reveals that LRMs exhibit limited effective reasoning length and struggle to allocate thinking budget across multiple problems appropriately. Recognizing these limitations, we use R-HORIZON to construct long-horizon reasoning data for <b>reinforcement learning with verified rewards (RLVR)</b>. Compared to training with single-horizon data, RLVR with R-HORIZON not only substantially improves performance on the multi-horizon reasoning tasks, but also promotes accuracy on standard reasoning tasks (+7.5 on AIME2024). These results position R-HORIZON as a scalable, controllable, and low-cost paradigm for enhancing and evaluating the long-horizon reasoning capabilities of LRMs.
              </p>
              <p>
                <img src="static/images/mainfig.png" alt="R-HORIZON Concept Illustration" class="blend-img-background center-image" style="max-width: 100%; height: auto;" loading="lazy" />
              </p>
            </div>
          </div>
        </div>
      </div>
    </section>
    ---

    <section id="overview" class="section hero is-small">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-full">
            <div class="content">
              <h2 class="title is-3">Overview</h2>
              <div class="level-set has-text-justified">
                <p>
                  Recent advances in reasoning-focused language models (e.g., OpenAI o1, DeepSeek-R1) have demonstrated remarkable improvements through test-time scaling and long Chain-of-Thought (CoT). However, existing benchmarks primarily focus on immediate, single-horizon tasks, failing to adequately evaluate models' ability to handle complex, long-horizon scenarios.
                </p>
                <p>
                  To address these limitations, we introduce <b>R-HORIZON</b>, which:
                  <ul>
                    <li>Transforms isolated problems into **complex multi-step reasoning scenarios** through query composition.</li>
                    <li>Establishes the **R-HORIZON Benchmark** comprising 6 representative datasets from mathematics, code generation, and agent applications.</li>
                    <li>Enables **reinforcement learning with verified rewards (RLVR)** using long-horizon reasoning data.</li>
                  </ul>
                  The diagram below illustrates our method of transforming single problems into complex chained scenarios.
                </p>
                <img src="static/images/method_fig.png" alt="R-HORIZON Method Diagram" class="blend-img-background center-image" style="max-width: 90%; height: auto; display: block; margin: 0 auto;" loading="lazy" />
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    ---

    <section id="evaluation" class="section hero is-small is-light">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-full">
            <div class="content">
              <h2 class="title is-3">Evaluation Results</h2>
              <div class="level-set has-text-justified">
                <p>
                  We evaluate 20+ state-of-the-art Large Reasoning Models (LRMs) on the R-HORIZON Benchmark, revealing a **significant performance degradation** as reasoning horizons increase. Key findings from our benchmark evaluation include:
                </p>
                <ul>
                  <li>**Universal Performance Degradation**: Even the most powerful models suffer severe drops as problem count increases. For instance, DeepSeek-R1 drops from 87.3% (single problem) to 24.6% (5 problems) on AIME25.</li>
                  <li>**Model Size Matters**: Larger models exhibit more resilience to multi-horizon challenges.</li>
                  <li>**Task-Dependent Degradation**: Code generation tasks show steeper performance declines compared to mathematics. Many reasoning models lose their tool-calling abilities in web search scenarios.</li>
                </ul>
                <p>
                  The plot below summarizes the performance across different reasoning horizons.
                </p>
                <img src="static/images/result_fig.png" alt="R-HORIZON Benchmark Results" class="blend-img-background center-image" style="max-width: 90%; height: auto; display: block; margin: 0 auto;" loading="lazy" />
              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    ---

    <section id="training" class="section hero is-small">
      <div class="container is-max-desktop">
        <div class="columns is-centered has-text-centered">
          <div class="column is-full">
            <div class="content">
              <h2 class="title is-3">Training with R-HORIZON</h2>
              <div class="level-set has-text-justified">
                <p>
                  We use R-HORIZON composed data for **Reinforcement Learning with Verified Rewards (RLVR)**. Training with this long-horizon data yields substantial improvements on both single and multi-horizon reasoning tasks, demonstrating the effectiveness of our method for enhancing LRM capabilities.
                </p>
                <p>
                  <b>Training Results Highlights:</b>
                  <ul>
                    <li>**Dual Performance Gains**: Training with 2-composed problems significantly improves both multi-horizon reasoning (<b>+17.4 points</b> on AIME24 n=2) and single-problem performance (<b>+7.5 points</b> on AIME24 original).</li>
                    <li>**Scalable Complexity**: Increasing composition complexity (n=4) enhances the model's ability to handle problems requiring more reasoning steps, achieving <b>50.6%</b> on Math500 (n=8).</li>
                  </ul>
                </p>
                <img src="static/images/skywork_n1_n2_comparison.png" alt="Training Comparison Plot" class="blend-img-background center-image" style="max-width: 90%; height: auto; display: block; margin: 0 auto;" loading="lazy" />
                
                <h3 class="title is-4" style="margin-top: 2rem;">Quantitative Results</h3>
                <table class="leaderboard-table" border="1" cellspacing="0" cellpadding="4" style="border-collapse: collapse; text-align: center; width: 100%;">
                    <thead>
                      <tr>
                        <th>Models</th>
                        <th>MATH500 (Origin)</th>
                        <th>MATH500 (n=8)</th>
                        <th>AIME24 (Origin)</th>
                        <th>AIME24 (n=2)</th>
                        <th>AIME25 (Origin)</th>
                        <th>AIME25 (n=2)</th>
                        <th>AMC23 (Origin)</th>
                        <th>AMC23 (n=2)</th>
                      </tr>
                    </thead>
                    <tbody>
                      <tr><td>R1-Qwen-7B</td><td>93.6</td><td>11.8</td><td>48.3</td><td>16.4</td><td>33.3</td><td>3.5</td><td>90.2</td><td>48.8</td></tr>
                      <tr><td>Baseline (n=1)</td><td>95.6</td><td>8.4</td><td>57.9</td><td>16.7</td><td>47.9</td><td>5.1</td><td><b>95.9</b></td><td>55.0</td></tr>
                      <tr><td>R-HORIZON (n=2)</td><td>95.4</td><td>21.4</td><td><b>65.4</b></td><td>34.1</td><td><b>49.6</b></td><td>10.0</td><td>94.1</td><td>80.6</td></tr>
                      <tr><td>R-HORIZON (n=4)</td><td>94.6</td><td><b>50.6</b></td><td>62.9</td><td>34.8</td><td>45.4</td><td>8.1</td><td>91.9</td><td>79.1</td></tr>
                    </tbody>
                </table>

              </div>
            </div>
          </div>
        </div>
      </div>
    </section>

    ---

    <section class="section" id="BibTeX">
      <div class="container is-max-desktop content">
        <div class="bibtex-header">
          <h2 class="title">BibTeX</h2>
          <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
            <i class="fas fa-copy"></i>
            <span class="copy-text">Copy</span>
          </button>
        </div>
        <pre id="bibtex-code"><code>@article{lu2025rhorizon,
  title={R-HORIZON: How Far Can Your Large Reasoning Model Really Go in Breadth and Depth?},
  author={Lu, Yi and Wang, Jianing and Guo, Linsen and He, Wei and Tang, Hongyin and Gui, Tao and Huang, Xuanjing and Cao, Xuezhi and Wang, Wei and Cai, Xunliang},
  journal={arXiv preprint arXiv:[请替换为您的 arXiv ID]},
  year={2025}
}
</code></pre>
      </div>
    </section>
    <footer class="footer">
      <div class="container">
        <div class="columns is-centered">
          <div class="column is-8">
            <div class="content">

              <p>
                This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                  target="_blank">Academic Project Page Template</a> which was adopted from the <a
                  href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              </p>

            </div>
          </div>
        </div>
      </div>
    </footer>

    </main>
</body>

</html>
